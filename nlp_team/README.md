# NLP Team
The NLP Team, in collaboration with the [Crypto Team](https://github.com/OpenMined/Roadmap/tree/master/crypto_team), is on a mission to help bring privacy-preserving NLP to life. [SyferText](https://github.com/OpenMined/SyferText) is the library the team is currently building in an effort to create the first production-ready solution leveraging [PySyft](https://github.com/OpenMined/PySyft) to enable Natural Language Process that protects data and models' privacy.

## Roadmap (2020)

1. Building SyferText with production in mind.
  - Identifying at least three companies with a potential interest in using SyferText.
  - Building a collaboration around a real-world usecase with at least one company.

2. Focus on communication: OpenMined AMA, meetups, tutorials.

## Team

<table>
  <tr>
    <td align="center">
      <a href="https://github.com/AlanAboudib">
        <img src="https://avatars1.githubusercontent.com/u/11991643?s=240" width="170px;" alt="Alan Aboudib avatar">
        <br /><sub><b>Alan Aboudib</b></sub></a><br />
        <sub>Team Lead / SyferText</sub>
      </a>
    </td>
    <td align="center">
      <a href="https://github.com/dzlab">
        <img src="https://avatars0.githubusercontent.com/u/1645304?s=400&v=4" width="170px;" alt="Bachir Chihani avatar">
        <br /><sub><b>Bachir Chihani</b></sub></a><br />
        <sub>SyferText</sub>
      </a>
    </td>
    <td align="center">
      <a href="https://github.com/MarcioPorto">
        <img src="https://avatars1.githubusercontent.com/u/6521281?s=400&v=4" width="170px;" alt="Marcio Porto avatar">
        <br /><sub><b>MÃ¡rcio Porto</b></sub></a><br />
        <sub>SyferText</sub>
      </a>
    </td>
  </tr>
  <tr>
</table>


## Short-Term Goals 

Here are some of the main SyferText features we are working on currently:

1. Perform the first encrypted federated training of a logistic regression model on two remote datasets (subsets of SST-2). *(Before March 19th 2020)*

2. Validate that such concurrent training on two datasets can boost performance compared to pretraining on one and fine tuning on the other. *(Before March 19th 2020)*

3. The ability to add the trained model to a pipeline of models that operate an a document. *(Before March 19th 2020)*

4. The ability to dump/load a language model with all of its pipes to/from disk. *(Before May 13th 2020)*


## Events

- **(October 26th, 2019)** [DevFest2019, Reading, UK](https://www.meetup.com/GDG-Reading-Thames-Valley/events/262918960/).

Demo on remote blind tokenization with SyferText.


- **(March 19th, 2020)** [GDG Meetup, Reading, UK](https://www.meetup.com/GDG-Reading-Thames-Valley/events/268137223/).

Demo on sentiment analysis with SyferText on multiple private datasets.


- **(May 13th)**: [OpenMined AMA](https://www.youtube.com/channel/UCzoUqDE_OzYo6lGXtsEbOxQ).

